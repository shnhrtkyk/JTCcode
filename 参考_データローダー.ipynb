{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJYzL8r21HJv8YBmUoxnGY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shnhrtkyk/JTCcode/blob/main/%E5%8F%82%E8%80%83_%E3%83%87%E3%83%BC%E3%82%BF%E3%83%AD%E3%83%BC%E3%83%80%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRRo6KnDk51M"
      },
      "outputs": [],
      "source": [
        "class PointDataset(data.Dataset):\n",
        "\n",
        "    ATTR_EXLUSION_LIST = ['X', 'Y', 'Z','red', 'green', 'blue',\n",
        "                          'flag_byte', 'scan_angle_rank', 'user_data',\n",
        "                          'pt_src_id', 'gps_time']\n",
        "    ATTR_EXTRA_LIST = ['num_returns']\n",
        "    def __init__(self, root, npoints=20000, transform=None):\n",
        "        self.npoints = npoints\n",
        "        self.root = root\n",
        "        self.pointlist = []\n",
        "        self.rgblist = []\n",
        "        self.datalist = []\n",
        "        \n",
        "        self.transform = transform\n",
        "        self.pointpath = root + \"/pointcloud_path/\"\n",
        "        print(self.pointpath )\n",
        "        self.point_list  = glob.glob(self.pointpath + \"/*.las\")[:]\n",
        "        print(self.point_list )\n",
        "        count = 0\n",
        "        for file in self.point_list:\n",
        "            print(file)\n",
        "            # point cloud 取得\n",
        "            file_h = laspy.file.File(file, mode='r')\n",
        "            print(file_h.header.min[0])\n",
        "            print(file_h.header.min[2])\n",
        "            print(file_h.header.min[1])\n",
        "            src = np.vstack([file_h.x, file_h.y, file_h.z]).transpose()\n",
        "            if(len(src)<npoints):continue\n",
        "            rgb = np.vstack([file_h.red, file_h.green, file_h.blue]).transpose()\n",
        "            rgb = rgb/255.0\n",
        "            print(np.amin(rgb, axis=0))\n",
        "            print(np.amax(rgb, axis=0))\n",
        "            points = file_h.points['point']\n",
        "            # 使用する次元の選択\n",
        "            attr_names = [a for a in points.dtype.names] + ATTR_EXTRA_LIST\n",
        "            features = np.array([getattr(file_h, name) for name in attr_names\n",
        "                                if name not in ATTR_EXLUSION_LIST]).transpose()\n",
        "            \n",
        "            print(features[:,1])\n",
        "            features = features/1.0\n",
        "            names = [name for name in attr_names if name not in ATTR_EXLUSION_LIST]\n",
        "            print(names)\n",
        "\n",
        "            file_h.close()\n",
        "            # ノイズ除去\n",
        "            pcd = o3d.geometry.PointCloud()\n",
        "            pcd.points = o3d.utility.Vector3dVector(src)\n",
        "            pcd.colors = o3d.utility.Vector3dVector(rgb)\n",
        "            # cl, ind = pcd.remove_radius_outlier(nb_points=16, radius=0.05)\n",
        "            cl, ind = pcd.remove_statistical_outlier(nb_neighbors=20,\n",
        "                                                        std_ratio=2.0)\n",
        "            pcd = pcd.select_down_sample(ind)\n",
        "            src = np.asarray(pcd.points)\n",
        "            rgb = np.asarray(pcd.colors)\n",
        "            normlized_xyz = np.zeros((npoints, 3))\n",
        "            normlized_rgb = np.zeros((npoints, 3))\n",
        "            normlized_feature = np.zeros((npoints, 3))\n",
        "            self.coord_min, self.coord_max = np.amin(src, axis=0)[:3], np.amax(src, axis=0)[:3]\n",
        "            \n",
        "            if(self.coord_max[0]==0):continue\n",
        "            if(self.coord_max[1]==0):continue\n",
        "            if(self.coord_max[2]==0):continue\n",
        "            print(np.amin(src, axis=0)[:3] )\n",
        "            print(np.amax(src, axis=0)[:3] )\n",
        "            #　正規化\n",
        "            src[:, 0] = ((src[:, 0] - self.coord_min[0])/30.0) - 0.5\n",
        "            src[:, 1] = ((src[:, 1] - self.coord_min[1])/30.0) - 0.5\n",
        "            src[:, 2] = ((src[:, 2] - self.coord_min[2])/30.0) \n",
        "            features[:,0] = features[:,0]/ 4000.0 #'intensity', 'raw_classification', 'num_returns']\n",
        "            features[:,1] = features[:,1]/ 17.0\n",
        "            features[:,2] = features[:,2]/ 8.0\n",
        "\n",
        "\n",
        "            print(np.amin(src, axis=0)[:3] )\n",
        "            print(np.amax(src, axis=0)[:3] )\n",
        "            if(len(src) >=npoints):\n",
        "                normlized_xyz[:,:]=src[:npoints,:]\n",
        "                normlized_rgb[:,:]=rgb[:npoints,:]\n",
        "                normlized_feature[:,:] = features[:npoints,:]\n",
        "            else:\n",
        "                normlized_xyz[:len(src),:]=src[:,:]\n",
        "\n",
        "            self.pointlist.append(normlized_xyz)\n",
        "            self.rgblist.append(normlized_rgb)\n",
        "            normlized_xyz = torch.from_numpy(normlized_xyz).float()\n",
        "            random_features = torch.randn(npoints,6)\n",
        "            random_features[:, :3] = torch.from_numpy(normlized_feature).float()\n",
        "\n",
        "            self.datalist.append(Data(pos=normlized_xyz[:, :], x=random_features[ :, :3]))\n",
        "\n",
        "                \n",
        "\n",
        "        self.data_num = len(self.pointlist)\n",
        "        \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        point = self.pointlist[index]\n",
        "        point = torch.from_numpy(point)\n",
        "        geom = self.datalist[index]\n",
        "        return rgb, point, geom\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pointlist)\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "train_dataset = ImgtoPointDataset(root=\"/path/to/root/\",transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True,\n",
        "                          num_workers=16)"
      ]
    }
  ]
}