{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shnhrtkyk/JTCcode/blob/main/05_%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%81%AB%E3%82%88%E3%82%8B%E7%82%B9%E7%BE%A4%E3%81%AE%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s1miMjSd91R"
      },
      "source": [
        "# 点群の分類を行う深層学習手法"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここでは、入力された点群がどのようなクラスであるかを予測する点群の分類タスクを行います。例えば、ロボットの目の前にある物体を計測した点群がなんのクラスなのかがわかれば、ロボットの行動を最適に行えます。"
      ],
      "metadata": {
        "id": "QiuRcm753WoT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSjF8zBBd5Cx"
      },
      "source": [
        "## 点群に対する深層学習手法のライブラリインストール"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このノートブックではPytorchと、Pytorch向けの3次元点群処理用ライブラリであるPytorch Geometricを用います。"
      ],
      "metadata": {
        "id": "KnA3pN2B1Uxa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6omvItcSd0FZ"
      },
      "outputs": [],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install tensorboardX\n",
        "\n",
        "# Helper functions for visualization.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# 可視化に関する関数を作成\n",
        "def visualize_mesh(pos, face):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(projection='3d')\n",
        "    ax.axes.xaxis.set_ticklabels([])\n",
        "    ax.axes.yaxis.set_ticklabels([])\n",
        "    ax.axes.zaxis.set_ticklabels([])\n",
        "    ax.plot_trisurf(pos[:, 0], pos[:, 1], pos[:, 2], triangles=data.face.t(), antialiased=False)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_points(pos, edge_index=None, index=None):\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    if edge_index is not None:\n",
        "        for (src, dst) in edge_index.t().tolist():\n",
        "             src = pos[src].tolist()\n",
        "             dst = pos[dst].tolist()\n",
        "             plt.plot([src[0], dst[0]], [src[1], dst[1]], linewidth=1, color='black')\n",
        "    if index is None:\n",
        "        plt.scatter(pos[:, 0], pos[:, 1], s=50, zorder=1000)\n",
        "    else:\n",
        "       mask = torch.zeros(pos.size(0), dtype=torch.bool)\n",
        "       mask[index] = True\n",
        "       plt.scatter(pos[~mask, 0], pos[~mask, 1], s=50, color='lightgray', zorder=1000)\n",
        "       plt.scatter(pos[mask, 0], pos[mask, 1], s=50, zorder=1000)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLbp5piOeFx_"
      },
      "source": [
        "## データをダウンロード"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "点群の分類タスク向けの公開データセットであるModelNetを用います。ModelNetは家具や家電などの3Dモデルから仮想的に作成した点群のデータで、点群とそれに対応するクラス情報が紐づいています。ModelNetには分類するクラス数が違うデータセットがあり、ここでは簡単な10クラス分類のデータセットを用います。\n",
        "※ダウンロードに時間がかかります。"
      ],
      "metadata": {
        "id": "B01AkSif3znh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LejEjt7Idil5"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from torch_geometric.datasets import ModelNet\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "current_path = Path.cwd()\n",
        "dataset_dir = current_path / \"modelnet10\"\n",
        "\n",
        "pre_transform = T.Compose([\n",
        "    T.SamplePoints(1024, remove_faces=True, include_normals=True),\n",
        "    T.NormalizeScale(),\n",
        "])\n",
        "# name で使用するModelNetの種類を選択する。\n",
        "train_dataset = ModelNet(dataset_dir, name=\"10\", train=True, transform=None, pre_transform=pre_transform, pre_filter=None)\n",
        "test_dataset = ModelNet(dataset_dir, name=\"10\", train=False, transform=None, pre_transform=pre_transform, pre_filter=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "分類するクラスは以下のようにIDが降られています。"
      ],
      "metadata": {
        "id": "zMF0H_qz8Z8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path(\"/content/modelnet10/raw\")\n",
        "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
        "classes = {folder: i for i, folder in enumerate(folders)}\n",
        "classes"
      ],
      "metadata": {
        "id": "VEESACSE70tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkLElgjA5aiB"
      },
      "source": [
        "### データの確認"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "データセットとして読み込んだModelNetから点群を取得して可視化します。\n",
        "今回は訓練データの1000番目の点群を可視化してみます。"
      ],
      "metadata": {
        "id": "ZsmXMf7n8nIo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww8Ebgpw5bDQ"
      },
      "outputs": [],
      "source": [
        "tmp =  train_dataset[1000]\n",
        "print(tmp.y)\n",
        "point = tmp.pos\n",
        "x = point[:, 0]\n",
        "y = point[:, 1]\n",
        "z = point[:, 2]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import proj3d\n",
        "\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(x, y, z)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "訓練データの数を確認します。"
      ],
      "metadata": {
        "id": "_B78FamB81aw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw29j54Fdil7"
      },
      "outputs": [],
      "source": [
        "print(\"train_dataset len:\", len(train_dataset))\n",
        "print(train_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch Geometricで読み込んだ点群データの扱い方について説明します。\n",
        "`.pos`がXYZ座標を保持しています。 N点×XYZ座標の行列です。\n"
      ],
      "metadata": {
        "id": "7oF0T16d84wI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brptd_wwdil8"
      },
      "outputs": [],
      "source": [
        "print(train_dataset[0].pos.shape)\n",
        "print(train_dataset[0].pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に、PytorchGeometricのデータ読み込みについて説明します。\n",
        "深層学習のモデルを学習する際には、バッチと呼ばれる小さなデータ単位で処理を行います。今回はバッチサイズを32として、一回の学習に32個の点群を呼び出します。\n",
        "\n"
      ],
      "metadata": {
        "id": "OIBlDU1U9Vq5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gBtZFW9dil8"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import DataLoader as DataLoader\n",
        "dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "batch = next(iter(dataloader))\n",
        "print(batch)\n",
        "print(batch.pos)# 座標\n",
        "print(batch.y) # 真値ラベル"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PointNetの層設計"
      ],
      "metadata": {
        "id": "8sm1sApDJ9qd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 層設計"
      ],
      "metadata": {
        "id": "XoPp0bVmKJCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### シンメトリック関数"
      ],
      "metadata": {
        "id": "mP0KUZb6KJCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず、入力された点群の順番に対する依存を抜くためのシンメトリック関数を実装します。ここでは、シンメトリック関数としてMaxPoolingを使用します。"
      ],
      "metadata": {
        "id": "1k52T2yHWBhq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjDBJWekKJCq"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import global_max_pool\n",
        "import torch.nn as nn\n",
        "\n",
        "class SymmFunction(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SymmFunction, self).__init__()\n",
        "        self.shared_mlp = nn.Sequential(\n",
        "            nn.Linear(3, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
        "            nn.Linear(64, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
        "            nn.Linear(128, 512),\n",
        "        )\n",
        "        \n",
        "    def forward(self, batch):\n",
        "        x = self.shared_mlp(batch.pos)\n",
        "        x = global_max_pool(x, batch.batch)\n",
        "        return x\n",
        "\n",
        "f = SymmFunction()\n",
        "print(batch)\n",
        "y = f(batch)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TNet"
      ],
      "metadata": {
        "id": "1lBHhn9PKJCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TNetは入力された点群の剛体変形を吸収するために開発された関数です。\n"
      ],
      "metadata": {
        "id": "4tUY-5MXkeC-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_rg4pb1KJCq"
      },
      "outputs": [],
      "source": [
        "class InputTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InputTNet, self).__init__()\n",
        "        self.input_mlp = nn.Sequential(\n",
        "            nn.Linear(3, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
        "            nn.Linear(64, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
        "            nn.Linear(128, 1024), nn.BatchNorm1d(1024), nn.ReLU(),\n",
        "        )\n",
        "        self.output_mlp = nn.Sequential(\n",
        "            nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(),\n",
        "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "            nn.Linear(256, 9)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x, batch):\n",
        "        x = self.input_mlp(x)\n",
        "        x = global_max_pool(x, batch)\n",
        "        x = self.output_mlp(x)\n",
        "        x = x.view(-1, 3, 3)\n",
        "        id_matrix = torch.eye(3).to(x.device).view(1, 3, 3).repeat(x.shape[0], 1, 1)\n",
        "        x = id_matrix + x\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TNet(特徴量)"
      ],
      "metadata": {
        "id": "pwAM9ny2KJCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TNetは点群の幾何的な変形だけでなく、特徴量空間でも適用することで剛体変形の影響を削減します。\n"
      ],
      "metadata": {
        "id": "L2jEuF0Bklle"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UntR2ur1KJCr"
      },
      "outputs": [],
      "source": [
        "class FeatureTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureTNet, self).__init__()\n",
        "        self.input_mlp = nn.Sequential(\n",
        "            nn.Linear(64, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
        "            nn.Linear(64, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
        "            nn.Linear(128, 1024), nn.BatchNorm1d(1024), nn.ReLU(),\n",
        "        )\n",
        "        self.output_mlp = nn.Sequential(\n",
        "            nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(),\n",
        "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "            nn.Linear(256, 64*64)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x, batch):\n",
        "        x = self.input_mlp(x)\n",
        "        x = global_max_pool(x, batch)\n",
        "        x = self.output_mlp(x)\n",
        "        x = x.view(-1, 64, 64)\n",
        "        id_matrix = torch.eye(64).to(x.device).view(1, 64, 64).repeat(x.shape[0], 1, 1)\n",
        "        x = id_matrix + x\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PointNetの本体"
      ],
      "metadata": {
        "id": "c4QfxJ0f6aJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PointNetは非常に単純な構造を持っています。\n",
        "入力された点群の各点に対して、MLPを適用し、その後にシンメトリック関数であるマックスプーリングによって入力された点群の順番に関する依存を抜きます。\n",
        "また、TNetを入力された点群に適用し、さらに特徴量空間でも適用します。します。"
      ],
      "metadata": {
        "id": "YFIxaSzHktXW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37Q0JtJedil-"
      },
      "outputs": [],
      "source": [
        "class PointNetClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PointNetClassification, self).__init__()\n",
        "        # TNet\n",
        "        self.input_tnet = InputTNet()\n",
        "        # 各点に適用するMLP\n",
        "        self.mlp1 = nn.Sequential(\n",
        "            nn.Linear(3, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
        "            nn.Linear(64, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
        "        )\n",
        "        self.feature_tnet = FeatureTNet()\n",
        "        # 各点に適用するMLP\n",
        "        self.mlp2 = nn.Sequential(\n",
        "            nn.Linear(64, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
        "            nn.Linear(64, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
        "            nn.Linear(128, 1024), nn.BatchNorm1d(1024), nn.ReLU(),\n",
        "        )\n",
        "        # 各点に適用するMLP\n",
        "        self.mlp3 = nn.Sequential(\n",
        "            nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(p=0.3),\n",
        "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(p=0.3),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "        \n",
        "    def forward(self, batch_data):\n",
        "        x = batch_data.pos\n",
        "        # まずTNetで変換する\n",
        "        input_transform = self.input_tnet(x, batch_data.batch)\n",
        "        transform = input_transform[batch_data.batch, :, :]\n",
        "        x = torch.bmm(transform, x.view(-1, 3, 1)).view(-1, 3)\n",
        "\n",
        "        # 各点に適用するMLP\n",
        "        x = self.mlp1(x)\n",
        "        \n",
        "        feature_transform = self.feature_tnet(x, batch_data.batch)\n",
        "        transform = feature_transform[batch_data.batch, :, :]\n",
        "        x = torch.bmm(transform, x.view(-1, 64, 1)).view(-1, 64)\n",
        "\n",
        "        x = self.mlp2(x)        \n",
        "\n",
        "        # シンメトリック関数であるマックスプーリングで順番の依存を抜く\n",
        "        x = global_max_pool(x, batch_data.batch)\n",
        "        x = self.mlp3(x)\n",
        "        \n",
        "        return x, input_transform, feature_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PointNetの訓練"
      ],
      "metadata": {
        "id": "dQAnwgBflfeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデルの呼び出しなど"
      ],
      "metadata": {
        "id": "da9r9iBelfeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rs7I3cvKlfeL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "num_epoch = 3\n",
        "batch_size = 32\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model = PointNetClassification()\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=num_epoch // 4, gamma=0.5)\n",
        "\n",
        "log_dir = current_path / \"log_modelnet10_classification_pointnet\"\n",
        "log_dir.mkdir(exist_ok=True)\n",
        "writer = SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "criteria = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 訓練コード"
      ],
      "metadata": {
        "id": "mJv_-YAllfeM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oTMoH6wlfeM"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "    model = model.train()\n",
        "    \n",
        "    losses = []\n",
        "    for batch_data in tqdm(train_dataloader, total=len(train_dataloader)):\n",
        "        batch_data = batch_data.to(device)\n",
        "        this_batch_size = batch_data.batch.detach().max() + 1\n",
        "        \n",
        "        pred_y, _, feature_transform = model(batch_data)\n",
        "        true_y = batch_data.y.detach()\n",
        "\n",
        "        class_loss = criteria(pred_y, true_y)\n",
        "        accuracy = float((pred_y.argmax(dim=1) == true_y).sum()) / float(this_batch_size)\n",
        "\n",
        "        id_matrix = torch.eye(feature_transform.shape[1]).to(feature_transform.device).view(1, 64, 64).repeat(feature_transform.shape[0], 1, 1)\n",
        "        transform_norm = torch.norm(torch.bmm(feature_transform, feature_transform.transpose(1, 2)) - id_matrix, dim=(1, 2))\n",
        "        reg_loss = transform_norm.mean()\n",
        "\n",
        "        loss = class_loss + reg_loss * 0.001\n",
        "        \n",
        "        losses.append({\n",
        "            \"loss\": loss.item(),\n",
        "            \"class_loss\": class_loss.item(),\n",
        "            \"reg_loss\": reg_loss.item(),\n",
        "            \"accuracy\": accuracy,\n",
        "            \"seen\": float(this_batch_size)})\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "        \n",
        "    if (epoch % 1 == 0):\n",
        "        model_path = log_dir / f\"model_{epoch:06}.pth\"\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "    \n",
        "    loss = 0\n",
        "    class_loss = 0\n",
        "    reg_loss = 0\n",
        "    accuracy = 0\n",
        "    seen = 0\n",
        "    for d in losses:\n",
        "        seen = seen + d[\"seen\"]\n",
        "        loss = loss + d[\"loss\"] * d[\"seen\"]\n",
        "        class_loss = class_loss + d[\"class_loss\"] * d[\"seen\"]\n",
        "        reg_loss = reg_loss + d[\"reg_loss\"] * d[\"seen\"]\n",
        "        accuracy = accuracy + d[\"accuracy\"] * d[\"seen\"]\n",
        "    loss = loss / seen\n",
        "    class_loss = class_loss / seen\n",
        "    reg_loss = reg_loss / seen\n",
        "    accuracy = accuracy / seen\n",
        "    writer.add_scalar(\"train_epoch/loss\", loss, epoch)\n",
        "    writer.add_scalar(\"train_epoch/class_loss\", class_loss, epoch)\n",
        "    writer.add_scalar(\"train_epoch/reg_loss\", reg_loss, epoch)\n",
        "    writer.add_scalar(\"train_epoch/accuracy\", accuracy, epoch)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model = model.eval()\n",
        "\n",
        "        losses = []\n",
        "        for batch_data in tqdm(test_dataloader, total=len(test_dataloader)):\n",
        "            batch_data = batch_data.to(device)\n",
        "            this_batch_size = batch_data.batch.detach().max() + 1\n",
        "\n",
        "            pred_y, _, feature_transform = model(batch_data)\n",
        "            true_y = batch_data.y.detach()\n",
        "\n",
        "            class_loss = criteria(pred_y, true_y)\n",
        "            accuracy =float((pred_y.argmax(dim=1) == true_y).sum()) / float(this_batch_size)\n",
        "\n",
        "            id_matrix = torch.eye(feature_transform.shape[1]).to(feature_transform.device).view(1, 64, 64).repeat(feature_transform.shape[0], 1, 1)\n",
        "            transform_norm = torch.norm(torch.bmm(feature_transform, feature_transform.transpose(1, 2)) - id_matrix, dim=(1, 2))\n",
        "            reg_loss = transform_norm.mean()\n",
        "\n",
        "            loss = class_loss + reg_loss * 0.001\n",
        "\n",
        "            losses.append({\n",
        "                \"loss\": loss.item(),\n",
        "                \"class_loss\": class_loss.item(),\n",
        "                \"reg_loss\": reg_loss.item(),\n",
        "                \"accuracy\": accuracy,\n",
        "                \"seen\": float(this_batch_size)})\n",
        "            \n",
        "        loss = 0\n",
        "        class_loss = 0\n",
        "        reg_loss = 0\n",
        "        accuracy = 0\n",
        "        seen = 0\n",
        "        for d in losses:\n",
        "            seen = seen + d[\"seen\"]\n",
        "            loss = loss + d[\"loss\"] * d[\"seen\"]\n",
        "            class_loss = class_loss + d[\"class_loss\"] * d[\"seen\"]\n",
        "            reg_loss = reg_loss + d[\"reg_loss\"] * d[\"seen\"]\n",
        "            accuracy = accuracy + d[\"accuracy\"] * d[\"seen\"]\n",
        "        loss = loss / seen\n",
        "        class_loss = class_loss / seen\n",
        "        reg_loss = reg_loss / seen\n",
        "        accuracy = accuracy / seen\n",
        "        writer.add_scalar(\"test_epoch/loss\", loss, epoch)\n",
        "        writer.add_scalar(\"test_epoch/class_loss\", class_loss, epoch)\n",
        "        writer.add_scalar(\"test_epoch/reg_loss\", reg_loss, epoch)\n",
        "        writer.add_scalar(\"test_epoch/accuracy\", accuracy, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63xCTDAF6JoQ"
      },
      "source": [
        "## PointNet++の層設計"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここからは、深層学習モデルの構築に移ります。PytorchGeometricを用いて実際にPointNet++を実装してみます。"
      ],
      "metadata": {
        "id": "2faNlfyb9_uY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kOowuH56Rdo"
      },
      "source": [
        "### サブサンプリング関数"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PointNet++では、サブサンプリングを階層的に行いながら特徴量の算出を行います。\n",
        "Pytorch Geometricでは、最遠点サンプリング（FPSsampling）が関数として定義されています。\n",
        "PointNet++では、FPSによサブサンプリングする点の選択、選択された点の周辺にある点を探す処理、周辺点の特徴量を選択された点へ集約する、の流れで処理を行います。"
      ],
      "metadata": {
        "id": "2SLxQ6s_-KkY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDNIPFSEdil8"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import MLP, PointNetConv, fps, global_max_pool, radius\n",
        "class SAModule(torch.nn.Module):\n",
        "    def __init__(self, ratio, r, nn):\n",
        "        super().__init__()\n",
        "        self.ratio = ratio\n",
        "        self.r = r\n",
        "        self.conv = PointNetConv(nn, add_self_loops=False)\n",
        "\n",
        "    def forward(self, x, pos, batch):\n",
        "        idx = fps(pos, batch, ratio=self.ratio)\n",
        "        row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n",
        "                          max_num_neighbors=64)\n",
        "        edge_index = torch.stack([col, row], dim=0)\n",
        "        x_dst = None if x is None else x[idx]\n",
        "        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
        "        pos, batch = pos[idx], batch[idx]\n",
        "        return x, pos, batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-1wU50r6Uxn"
      },
      "source": [
        "### グローバルサブサンプリング"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "グローバルサンプリングでは、各点で算出した特徴量を、ひとつのベクトルへ集約することでクラス分類が実行できます。"
      ],
      "metadata": {
        "id": "wmgFVvXh-9TQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKjoGlTXdil9"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GlobalSAModule(torch.nn.Module):\n",
        "    def __init__(self, nn):\n",
        "        super().__init__()\n",
        "        self.nn = nn\n",
        "\n",
        "    def forward(self, x, pos, batch):\n",
        "        x = self.nn(torch.cat([x, pos], dim=1))\n",
        "        x = global_max_pool(x, batch)\n",
        "        pos = pos.new_zeros((x.size(0), 3))\n",
        "        batch = torch.arange(x.size(0), device=batch.device)\n",
        "        return x, pos, batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlyTmYKb6WGp"
      },
      "source": [
        "### PointNet++の本体"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記で定義したサブサンプリングを繰り返し適用します。"
      ],
      "metadata": {
        "id": "rhBLpl19_Qo3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y0uOAH-dil9"
      },
      "outputs": [],
      "source": [
        "class PointNet2Classification(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Input channels account for both `pos` and node features.\n",
        "        self.sa1_module = SAModule(0.5, 0.2, MLP([3, 64, 64, 128]))\n",
        "        self.sa2_module = SAModule(0.25, 0.4, MLP([128 + 3, 128, 128, 256]))\n",
        "        self.sa3_module = GlobalSAModule(MLP([256 + 3, 256, 512, 1024]))\n",
        "\n",
        "        self.mlp = MLP([1024, 512, 256, 10], dropout=0.5, norm=None)\n",
        "\n",
        "    def forward(self, data):\n",
        "        sa0_out = (data.x, data.pos, data.batch)\n",
        "        sa1_out = self.sa1_module(*sa0_out)\n",
        "        sa2_out = self.sa2_module(*sa1_out)\n",
        "        sa3_out = self.sa3_module(*sa2_out)\n",
        "        x, pos, batch = sa3_out\n",
        "\n",
        "        return self.mlp(x).log_softmax(dim=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTtQvaUL6eKh"
      },
      "source": [
        "## PointNet++の訓練"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKD9-20k6fm3"
      },
      "source": [
        "### モデルの呼び出しなど"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2n23EJ7dil-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "num_epoch = 3 # 今回は3エポック回します。\n",
        "batch_size = 32\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model = PointNet2Classification()\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=num_epoch // 4, gamma=0.5)\n",
        "\n",
        "log_dir = current_path / \"log_modelnet10_classification_pointnet2\"\n",
        "log_dir.mkdir(exist_ok=True)\n",
        "writer = SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "criteria = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDpuw26t6iTY"
      },
      "source": [
        "### 訓練コード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8TRItTSdil_"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "    model = model.train()\n",
        "    \n",
        "    losses = []\n",
        "    for batch_data in tqdm(train_dataloader, total=len(train_dataloader)):\n",
        "        batch_data = batch_data.to(device)\n",
        "        this_batch_size = batch_data.batch.detach().max() + 1\n",
        "        \n",
        "        pred_y = model(batch_data)\n",
        "        true_y = batch_data.y.detach()\n",
        "\n",
        "        class_loss = criteria(pred_y, true_y)\n",
        "        accuracy = float((pred_y.argmax(dim=1) == true_y).sum()) / float(this_batch_size)\n",
        "\n",
        "        loss = class_loss \n",
        "        \n",
        "        losses.append({\n",
        "            \"loss\": loss.item(),\n",
        "            \"class_loss\": class_loss.item(),\n",
        "            \"accuracy\": accuracy,\n",
        "            \"seen\": float(this_batch_size)})\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "        \n",
        "    if (epoch % 1 == 0):\n",
        "        model_path = log_dir / f\"model_{epoch:06}.pth\"\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "    \n",
        "    loss = 0\n",
        "    class_loss = 0\n",
        "    accuracy = 0\n",
        "    seen = 0\n",
        "    for d in losses:\n",
        "        seen = seen + d[\"seen\"]\n",
        "        loss = loss + d[\"loss\"] * d[\"seen\"]\n",
        "        class_loss = class_loss + d[\"class_loss\"] * d[\"seen\"]\n",
        "        accuracy = accuracy + d[\"accuracy\"] * d[\"seen\"]\n",
        "    loss = loss / seen\n",
        "    class_loss = class_loss / seen\n",
        "    accuracy = accuracy / seen\n",
        "    writer.add_scalar(\"train_epoch/loss\", loss, epoch)\n",
        "    writer.add_scalar(\"train_epoch/class_loss\", class_loss, epoch)\n",
        "    writer.add_scalar(\"train_epoch/accuracy\", accuracy, epoch)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model = model.eval()\n",
        "\n",
        "        losses = []\n",
        "        for batch_data in tqdm(test_dataloader, total=len(test_dataloader)):\n",
        "            batch_data = batch_data.to(device)\n",
        "            this_batch_size = batch_data.batch.detach().max() + 1\n",
        "\n",
        "            pred_y = model(batch_data)\n",
        "            true_y = batch_data.y.detach()\n",
        "\n",
        "            class_loss = criteria(pred_y, true_y)\n",
        "            accuracy =float((pred_y.argmax(dim=1) == true_y).sum()) / float(this_batch_size)\n",
        "\n",
        "\n",
        "\n",
        "            loss = class_loss \n",
        "\n",
        "            losses.append({\n",
        "                \"loss\": loss.item(),\n",
        "                \"class_loss\": class_loss.item(),\n",
        "                \"accuracy\": accuracy,\n",
        "                \"seen\": float(this_batch_size)})\n",
        "            \n",
        "        loss = 0\n",
        "        class_loss = 0\n",
        "        accuracy = 0\n",
        "        seen = 0\n",
        "        for d in losses:\n",
        "            seen = seen + d[\"seen\"]\n",
        "            loss = loss + d[\"loss\"] * d[\"seen\"]\n",
        "            class_loss = class_loss + d[\"class_loss\"] * d[\"seen\"]\n",
        "            accuracy = accuracy + d[\"accuracy\"] * d[\"seen\"]\n",
        "        loss = loss / seen\n",
        "        class_loss = class_loss / seen\n",
        "        accuracy = accuracy / seen\n",
        "        writer.add_scalar(\"test_epoch/loss\", loss, epoch)\n",
        "        writer.add_scalar(\"test_epoch/class_loss\", class_loss, epoch)\n",
        "        writer.add_scalar(\"test_epoch/accuracy\", accuracy, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 結果の比較"
      ],
      "metadata": {
        "id": "30mY8JqssQ6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PointNetの結果"
      ],
      "metadata": {
        "id": "LU3eU3UdtjFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        " \n",
        " \n",
        "#TensorBoard起動（表示したいログディレクトリを指定）\n",
        "%tensorboard --logdir=\"/content/log_modelnet10_classification_pointnet\" --port 6006"
      ],
      "metadata": {
        "id": "MXWdz-2YszW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PointNet++の結果"
      ],
      "metadata": {
        "id": "r8P7L7LHtvCc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4UoXxbldil_"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        " \n",
        " \n",
        "#TensorBoard起動（表示したいログディレクトリを指定）\n",
        "%tensorboard --logdir=\"/content/log_modelnet10_classification_pointnet2\"  --port 6007"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i -P | grep 6006"
      ],
      "metadata": {
        "id": "N6kW0KbwtWwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill -9 "
      ],
      "metadata": {
        "id": "HWVnyZD_tjUS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}